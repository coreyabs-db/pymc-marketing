{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d0bc87",
   "metadata": {},
   "source": [
    "# Pareto/NBD Model\n",
    "The Pareto/Negative-Binomial Distribution model was the first Buy-Till-You-Die (BTYD) model for estimating non-contractual customer activity over a continuous time period. First introduced by Schmittlein, et. al. in 1987 and developed further by Bruce Hardie and Peter Fader, it is frequently used as a benchmark in CLV research due to its robust performance and wide range of functionality. For detailed derivations of this model please refer to\n",
    "[\"A Note on Deriving the Pareto/NBD Model and Related Expressions.\"](https://www.brucehardie.com/notes/009/pareto_nbd_derivations_2005-11-05.pdf)\n",
    "\n",
    "In this notebook we will use Bayesian inference to fit a Pareto/NBD model in PyMC-Marketing, and compare results with the frequentist [`lifetimes`](https://github.com/CamDavidsonPilon/lifetimes) library (no longer maintained). We will also demonstrate the predictive functionality of this model, along with an example for time-invariant covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbb64d-caf5-4993-a3cb-6d97bb4c835c",
   "metadata": {},
   "source": [
    "## Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1aa7d-a7d5-4404-acad-63e9604d8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import seaborn as sb\n",
    "import xarray as xr\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from lifetimes import ParetoNBDFitter\n",
    "\n",
    "from pymc_marketing import clv\n",
    "\n",
    "# Plotting configuration\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b916f1",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "In this notebook we will be using the CDNOW sample dataset, a popular benchmarking dataset in CLV and BTYD modeling research. Refer [here](https://www.brucehardie.com/notes/026/) for more information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb31ef",
   "metadata": {
    "id": "a374e74d"
   },
   "outputs": [],
   "source": [
    "url_cdnow = \"https://raw.githubusercontent.com/pymc-labs/pymc-marketing/main/data/cdnow_transactions.csv\"\n",
    "\n",
    "raw_data = pd.read_csv(url_cdnow)\n",
    "\n",
    "raw_data.info()\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b5a5c-f5d5-4dfb-bdce-6b6f12ff8e45",
   "metadata": {},
   "source": [
    "The only requirements for modeling spending behaviour with `ParetoNBDModel` are a customer identifier column, and a datetime column for each purchase. The number of CDs purchased and money spent per transaction could also be useful covariates, so we'll keep them in mind for later.\n",
    "\n",
    "It is common for customer transaction databases to also contain returns, discount values, etc., so let's do a quick validation check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc1545-7894-46f5-b06f-7f503c9ddce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d254dc-b4c1-41bc-84d7-d8f779e2d39f",
   "metadata": {},
   "source": [
    "Note there were some transactions with spend values of 0! Perhaps these were returns or promotional giveaways. Instances such as this are not true purchasing activities, and should be excluded from modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8cb9f-077d-4191-bb54-b068c3140080",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[raw_data[\"spent\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c693f9b-eaea-4e02-a4e2-798ff1612080",
   "metadata": {},
   "source": [
    "Use the `rfm_summary` utility to aggregate data for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_data = clv.rfm_summary(\n",
    "    raw_data,\n",
    "    customer_id_col=\"id\",\n",
    "    datetime_col=\"date\",\n",
    "    datetime_format=\"%Y%m%d\",\n",
    "    time_unit=\"W\",\n",
    ")\n",
    "\n",
    "rfm_data.info()\n",
    "rfm_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4dbf6-21a7-4009-9f3d-608e3b8a9a34",
   "metadata": {},
   "source": [
    "Recall the data aggregation definitions from the [CLV Quickstart](https://www.pymc-marketing.io/en/stable/notebooks/clv/clv_quickstart.html):\n",
    "\n",
    "- `customer_id` is an index of a unique identifiers for each customer.\n",
    "- `frequency` is the number of repeat purchases that a customer has made (i.e., total number of purchases minus one).\n",
    "- `recency` indicates the time period when a customer made their most recent purchase. If a customer has only made 1 purchase, recency is 0.\n",
    "- `T` is a customer's \"age\", or the number of time periods since their first purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b0672-8967-4ecc-9870-f8c08133f9ee",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "The Pareto/NBD model is based on the following assumptions for each customer:\n",
    "1. Customers are active for an unobserved period of time, then become permanently inactive.\n",
    "   \n",
    "#### Purchasing Process\n",
    "\n",
    "2. While active, the the number of transactions made by a customer follows a Poisson process with transaction rate $\\lambda$:\n",
    "   \n",
    "   $$P(X(t)=x|\\lambda) = \\frac{(\\lambda t)^{x}e^{-\\lambda t}}{x!}, x=0,1,2,...$$\n",
    "   \n",
    "   This is equivalent to assuming time between transactions is exponentially distributed with transaction rate $\\lambda$:\n",
    "   \n",
    "   $$f(t_{j}-t_{j-1}| \\lambda) = \\lambda e^{-\\lambda (t_{j} - t_{j - 1})}, \\quad t_{j} \\geq t_{j - 1} \\geq 0$$\n",
    "   \n",
    "   Where $t$ is the time period of the $j$th purchase.\n",
    "3. Heterogeneity in $\\lambda$ follows a Gamma distribution with shape parameter $r$ and scale parameter $\\alpha$:\n",
    "\n",
    "    $$g(\\lambda|r, \\alpha) = \\frac{\\alpha^{r}\\lambda^{r - 1}e^{-\\lambda \\alpha}}{\\Gamma(r)}$$\n",
    "#### Dropout Process\n",
    "4. The duration of a customer's unobserved active lifetime is exponentially distributed with dropout rate $\\mu$.\n",
    "\n",
    "5. Heterogeneity in $\\mu$ also follows a Gamma distribution with shape parameter $s$ and scale parameter $\\beta$:\n",
    "\n",
    "    $$g(\\mu|s, \\beta) = \\frac{\\beta^{s}\\mu^{s - 1}e^{-\\mu \\beta}}{\\Gamma(s)}$$\n",
    "   \n",
    "6. Transaction rate $\\lambda$ and time until dropout $\\mu$ vary independently for each customer.\n",
    "\n",
    "If we take the expectation across the distributions of $\\lambda$ and $\\mu$, we can derive a likelihood function to estimate parameters $r$, $\\alpha$, $s$, and $\\beta$ across the customer population. For more details on the `ParetoNBD` likelihood please refer to the [docs](https://www.pymc-marketing.io/en/stable/api/generated/pymc_marketing.clv.distributions.ParetoNBD.html#pymc_marketing.clv.distributions.ParetoNBD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee69f5b-1b9e-4aa4-bdd4-5358c866453c",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d5448",
   "metadata": {},
   "source": [
    "### `lifetimes` Benchmark Model\n",
    "\n",
    "Let's time travel back to July 2020 and use the old `lifetimes` library to fit a Pareto/NBD model with Maximum Likelihood Estimation (MLE). The `Nelder-Mead` optimizer from `scipy.optimize` is ran under the hood to estimate scalar values for $r$, $\\alpha$, $s$, and $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b39d06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "freq = rfm_data[\"frequency\"].values\n",
    "rec = rfm_data[\"recency\"].values\n",
    "T = rfm_data[\"T\"].values\n",
    "\n",
    "pnbd_lt = ParetoNBDFitter()\n",
    "pnbd_lt.fit(freq, rec, T)\n",
    "pnbd_lt.params_.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a1b1a",
   "metadata": {
    "id": "a2z_ZcC74wPI"
   },
   "source": [
    "The Bayesian equivalent of MLE is Maximum a Posteriori(MAP), in which the returned scalar values are regularized with priors during estimation.\n",
    "\n",
    "A \"Flat\" prior indicates the user is agnostic, holding no prior beliefs or assumptions about the data. $r$, $\\alpha$, $s$, and $\\beta$ must also be positive values, so let's configure our Bayesian `ParetoNBDModel` with `HalfFlat` priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2cca2-5c5f-4a64-98d8-71fc8720feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_config = {\n",
    "    \"r_prior\": {\"dist\": \"HalfFlat\", \"kwargs\": {}},\n",
    "    \"alpha_prior\": {\"dist\": \"HalfFlat\", \"kwargs\": {}},\n",
    "    \"s_prior\": {\"dist\": \"HalfFlat\", \"kwargs\": {}},\n",
    "    \"beta_prior\": {\"dist\": \"HalfFlat\", \"kwargs\": {}},\n",
    "}\n",
    "\n",
    "pnbd_pymc = clv.ParetoNBDModel(data=rfm_data, model_config=flat_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19230a77-e717-4bfb-91c0-ee163ad499dd",
   "metadata": {},
   "source": [
    "Build the model to view the choice of Priors used for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2da172-2f13-44d2-81ef-6658ccabe111",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_pymc.build_model()  # optional step\n",
    "pnbd_pymc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79320dc5-4188-427f-b3f6-1321f52fe193",
   "metadata": {},
   "source": [
    "Note it is not necessary to build a model prior to modeling.\n",
    "\n",
    "Now let's fit our `ParetoNBDModel` with MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42340959-cf08-4cd1-8ef1-9e5223e28c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_map = pnbd_pymc.fit(fit_method=\"map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510b7d1-3148-433d-8275-b65cc9794fbb",
   "metadata": {},
   "source": [
    "For MAP fitting `pymc-marketing` uses the `L_BGFS-B` optimizer from `scipy.optimize`, a faster and more stable alternative to `Nelder-Mead`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d063be9-d9a6-40fa-8dee-c03ca8b2d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_fit = pnbd_pymc.fit_summary()\n",
    "print(flat_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb398c-c980-400d-9178-9bc0c36e6a85",
   "metadata": {},
   "source": [
    "Model parameter estimations are equivalent between the frequentist MLE fit from `lifetimes`, and a Bayesian `pymc-marketing` model fit with flat priors. However, the CDNOW sample we're working with is quite small and comprises only 10% of the total CDNOW dataset, so it's quite likely these estimates are overfitting if we attempt to run predictions on the full dataset.\n",
    "\n",
    "With prior distributions, we can inform model fitting with our own subjective domain knowledge, and even improve the speed of model fits. The default prior configuration for `ParetoNBDModel` works well for a variety of use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a4db3-1bb2-42fc-bb1d-755907583603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_map = clv.ParetoNBDModel(data=rfm_data)\n",
    "pnbd_map.build_model()  # required for prior predictive checks\n",
    "pnbd_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e5ef6-8fac-43fa-8d54-d6cfa14f64a6",
   "metadata": {},
   "source": [
    "#### Prior and Posterior Predictive Checks\n",
    "PPCs allow us to check the efficacy of our priors, and the peformance of the fitted posteriors. PPCs aren't usually an option with MAP fitted models, but here we're actually sampling from the latent $\\lambda$ and $\\mu$ Gamma distributions, so PPCs are possible for `ParetoNBDModel` regardless of the fit method!\n",
    "\n",
    "Let's see how the model performs in a *prior* predictive check, where we sample from the default priors before fitting the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99916a-5170-465a-9e17-096340cf733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pnbd_map.model:\n",
    "    prior_idata = pm.sample_prior_predictive(random_seed=45, samples=1)\n",
    "\n",
    "obs_freq = prior_idata.observed_data[\"recency_frequency\"].sel(obs_var=\"frequency\")\n",
    "ppc_freq = prior_idata.prior_predictive[\"recency_frequency\"].sel(obs_var=\"frequency\")[\n",
    "    0\n",
    "][0]\n",
    "\n",
    "# PPC histogram plot\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Model Estimations\": ppc_freq.to_pandas().value_counts().sort_index(),\n",
    "        \"Observed\": obs_freq.to_pandas().value_counts().sort_index(),\n",
    "    }\n",
    ").head(15).plot(\n",
    "    kind=\"bar\",\n",
    "    title=\"Prior Predictive Check of Repeat Purchases per Customer\",\n",
    "    xlabel=\"Repeat Purchases per Customer\",\n",
    "    ylabel=\"Number of Customers\",\n",
    "    figsize=(12, 7),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea0ed6-dd5d-420e-91b3-54bc13790f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create axes for each companion plot\n",
    "_, axes = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(12, 7),\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "# ArviZ ECDF plot\n",
    "az.plot_ecdf(\n",
    "    ppc_freq,\n",
    "    obs_freq,\n",
    "    confidence_bands=True,\n",
    "    ax=axes[0],\n",
    "    fill_kwargs={\"label\": \"95% HDI\"},\n",
    "    plot_kwargs={\"label\": \"Observed\"},\n",
    ").set(\n",
    "    title=\"Prior Predictive ECDF Plot\",\n",
    "    xlabel=\"Purchases per Customer\",\n",
    "    ylabel=\"Percent of Total\",\n",
    ")\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "# ArviZ ECDF Diff plot\n",
    "az.plot_ecdf(\n",
    "    ppc_freq,\n",
    "    obs_freq,\n",
    "    confidence_bands=True,\n",
    "    difference=True,\n",
    "    ax=axes[1],\n",
    "    fill_kwargs={\"label\": \"95% HDI\"},\n",
    "    plot_kwargs={\"label\": \"Observed\"},\n",
    ").set(\n",
    "    title=\"Prior Predictive Difference Plot\",\n",
    "    xlabel=\"Purchases per Customer\",\n",
    "    ylabel=\"Percent Deviation from Expectation\",\n",
    ")\n",
    "axes[1].legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9efa2-ad01-4aeb-b498-fe92335e0d00",
   "metadata": {},
   "source": [
    "Here the `ParetoNBDModel` is simulating customer purchases from the prior distributions to compare against the obseved data. The priors we specified look reasonable for customers who have made 1-6 purchases, but does not model single-purchase customers well. The deviations beyond the confidence intervals of the Emperical Cumulative Distribution Function (ECDF) and Difference plots indicate the importance of single purchases customers - in fact they comprise over half the CDNOW sample dataset! \n",
    "\n",
    "Let's fit our model and run a *posterior* predictive check for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961724e-9f9e-4334-bbc8-c9b7bf1a0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_map.fit()\n",
    "map_fit = pnbd_map.fit_summary()  # save for plotting later\n",
    "\n",
    "obs_freq = pnbd_map.idata.observed_data[\"recency_frequency\"].sel(obs_var=\"frequency\")\n",
    "ppc_freq = pnbd_map.distribution_new_customer_recency_frequency(\n",
    "    rfm_data,\n",
    "    random_seed=42,\n",
    ").sel(chain=0, draw=0, obs_var=\"frequency\")\n",
    "\n",
    "# PPC histogram plot\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Model Estimations\": ppc_freq.to_pandas().value_counts().sort_index(),\n",
    "        \"Observed\": obs_freq.to_pandas().value_counts().sort_index(),\n",
    "    }\n",
    ").head(15).plot(\n",
    "    kind=\"bar\",\n",
    "    title=\"Posterior Predictive Check of Repeat Purchases per Customer\",\n",
    "    xlabel=\"Repeat Purchases per Customer\",\n",
    "    ylabel=\"Number of Customers\",\n",
    "    figsize=(12, 7),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f003f-3626-4f34-acb3-4c5b8b42be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create axes for each companion plot\n",
    "_, axes = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(12, 7),\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "# ArviZ ECDF plot\n",
    "az.plot_ecdf(\n",
    "    ppc_freq,\n",
    "    obs_freq,\n",
    "    confidence_bands=True,\n",
    "    ax=axes[0],\n",
    "    fill_kwargs={\"label\": \"95% HDI\"},\n",
    "    plot_kwargs={\"label\": \"Observed\"},\n",
    ").set(\n",
    "    title=\"Posterior Predictive ECDF Plot\",\n",
    "    xlabel=\"Purchases per Customer\",\n",
    "    ylabel=\"Percent of Total\",\n",
    ")\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "# ArviZ ECDF Diff plot\n",
    "az.plot_ecdf(\n",
    "    ppc_freq,\n",
    "    obs_freq,\n",
    "    confidence_bands=True,\n",
    "    difference=True,\n",
    "    ax=axes[1],\n",
    "    fill_kwargs={\"label\": \"95% HDI\"},\n",
    "    plot_kwargs={\"label\": \"Observed\"},\n",
    ").set(\n",
    "    title=\"Posterior Predictive Difference Plot\",\n",
    "    xlabel=\"Purchases per Customer\",\n",
    "    ylabel=\"Percent Deviation from Expectation\",\n",
    ")\n",
    "axes[1].legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697eb80-a45f-4503-ab8a-ca2aadbe294d",
   "metadata": {},
   "source": [
    "Our fitted model is able to reliably simulate customer behavior!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25724a17-538a-4ec5-9df8-8dd28b547a86",
   "metadata": {},
   "source": [
    "## Full Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c695d148-36b2-4731-94e4-15d673d6fc4d",
   "metadata": {},
   "source": [
    "MAP fits estimate only scalar values for $r$, $\\alpha$, $s$, and $\\beta$, but with full Bayesian sampling we can infer the posterior probability distributions for these parameters, illustrating uncertainty in our estimates as well as enabling prediction intervals.\n",
    "\n",
    "NUTS is the default sampler in `pymc-marketing`, which samples from the posterior by exploring the gradients of the probability space. However, NUTS sampling with `ParetoNBDModel` can be quite slow due to the complexity of the likelihood expression. In fact, the mathematical complexity of this model is what motivated the development of the [`BetaGeoModel`](https://www.pymc-marketing.io/en/stable/notebooks/clv/bg_nbd.html) in 2005. The BG/NBD model makes some simplifying assumptions and sacrifices functionality in customer dropout estimation for better computational performance.\n",
    "\n",
    "To save time and computational costs, it is recommended to use gradient-free methods such as `pm.DEMetropolisZ`. This often requires more samples during fitting, so if any `rhat statistic` warnings are encountered, increase the size of the `tune` and `draw` parameters until the warning no longer appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec3eb4-66d4-41ca-8ad0-e4a232767879",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_full = clv.ParetoNBDModel(data=rfm_data)\n",
    "pnbd_full.build_model()\n",
    "\n",
    "with pnbd_full.model:\n",
    "    pnbd_full.idata = pm.sample(\n",
    "        step=pm.DEMetropolisZ(),\n",
    "        tune=2500,\n",
    "        draws=3000,\n",
    "        idata_kwargs={\"log_likelihood\": True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbbde96-1b4d-47c5-9715-83fa76b2e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_full.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c94ec-0ae3-4055-801c-472c47053eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_trace(\n",
    "    data=pnbd_full.idata,\n",
    "    compact=True,\n",
    "    kind=\"rank_bars\",\n",
    "    backend_kwargs={\"figsize\": (12, 7), \"layout\": \"constrained\"},\n",
    ")\n",
    "plt.gcf().suptitle(\"Pareto/NBD Model Trace\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6f6a3-aed3-45c3-8b97-7fad2ce5b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_full.idata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deebe6f-2020-459e-a50b-72d9fa5c9db6",
   "metadata": {},
   "source": [
    "Let's see how the DEMZ posteriors compare to the MAP estimations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b786b-9e39-4cfa-ad43-5f0d0ca27e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(\n",
    "    nrows=2, ncols=2, figsize=(12, 7), sharex=False, sharey=False, layout=\"constrained\"\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var_name in enumerate([\"r\", \"alpha\", \"s\", \"beta\"]):\n",
    "    ax = axes[i]\n",
    "    az.plot_posterior(\n",
    "        pnbd_full.idata.posterior[var_name].values.flatten(),\n",
    "        color=\"C0\",\n",
    "        point_estimate=\"mean\",\n",
    "        ax=ax,\n",
    "        label=\"DEMZ\",\n",
    "    )\n",
    "    ax.axvline(x=map_fit[var_name], color=\"C1\", linestyle=\"--\", label=\"MAP\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_title(var_name)\n",
    "\n",
    "plt.gcf().suptitle(\"Pareto/NBD Model Parameters\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3ff94-83fe-4a6c-99ef-e25e0ee12cef",
   "metadata": {},
   "source": [
    "After fitting, models can be persisted for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c9649-c67c-4a07-a50d-ae0cf3e05317",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_pymc.save(\"pnbd.nc\")\n",
    "pnbd_pymc.load(\"pnbd.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d109c",
   "metadata": {},
   "source": [
    "## Predictive Methods\n",
    "\n",
    "The Pareto/NBD model supports a variety of predictive methods:\n",
    "\n",
    "- `expected_purchases`\n",
    "- `expected_probability_alive`\n",
    "- `expected_purchases_new_customer`\n",
    "- `expected_purchase_probability`\n",
    "\n",
    "Let's take a small sample of users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c440a8-b40d-4878-8ac8-674c37f2e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_customer_ids = [1, 5, 10, 18, 46, 1413]\n",
    "\n",
    "rfm_sample = rfm_data.query(\"customer_id.isin(@example_customer_ids)\")\n",
    "\n",
    "rfm_sample.sort_values(by=\"frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9afbb0-7f6a-4ff6-9825-553e200c1168",
   "metadata": {},
   "source": [
    "Observe customers 5 & 10 are *non-repeat buyers*, whereas 1413 and 46 are *frequent buyers*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7682d-758b-4001-b690-46663c276e9d",
   "metadata": {},
   "source": [
    "### Expected Number of Purchases\n",
    "Let's plot each customer's expected number of purchases over the next $90$ time periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e6a8a-2521-4b67-aaad-8bdce5d4fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = 90\n",
    "\n",
    "expected_purchases_over_time = xr.concat(\n",
    "    objs=[\n",
    "        pnbd_full.expected_purchases(\n",
    "            data=rfm_sample,\n",
    "            future_t=t,\n",
    "        )\n",
    "        for t in progress_bar(range(time_periods))\n",
    "    ],\n",
    "    dim=\"t\",\n",
    ").transpose(..., \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0f2bc-703d-422e-af22-68a52ffffee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(\n",
    "    nrows=len(example_customer_ids),\n",
    "    ncols=1,\n",
    "    figsize=(12, 14),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, customer_id in enumerate(example_customer_ids):\n",
    "    ax = axes[i]\n",
    "    customer_expected_purchases = expected_purchases_over_time.sel(\n",
    "        customer_id=customer_id\n",
    "    )\n",
    "    az.plot_hdi(\n",
    "        range(time_periods),\n",
    "        customer_expected_purchases,\n",
    "        hdi_prob=0.94,\n",
    "        color=\"C0\",\n",
    "        fill_kwargs={\"alpha\": 0.3, \"label\": \"$94 \\\\%$ HDI\"},\n",
    "        ax=ax,\n",
    "    )\n",
    "    az.plot_hdi(\n",
    "        range(time_periods),\n",
    "        customer_expected_purchases,\n",
    "        hdi_prob=0.5,\n",
    "        color=\"C0\",\n",
    "        fill_kwargs={\"alpha\": 0.5, \"label\": \"$50 \\\\%$ HDI\"},\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.plot(\n",
    "        range(time_periods),\n",
    "        customer_expected_purchases.mean(dim=(\"chain\", \"draw\")),\n",
    "        color=\"C0\",\n",
    "        label=\"posterior mean\",\n",
    "    )\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.set(title=f\"Customer {customer_id}\", xlabel=\"t\", ylabel=\"# of purchases\")\n",
    "\n",
    "axes[-1].set(xlabel=\"t\")\n",
    "plt.gcf().suptitle(\"Expected Number of Purchases\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6af96e-3b59-4c12-8478-a4c136a70db3",
   "metadata": {},
   "source": [
    "Note the HDI prediction intervals are only available if the model is fit with full posteriors.\n",
    "\n",
    "Observe the large number of purchases expected from the frequent buyers (Customers 46 and 1413) whereas little or no future activity is expected of the remaining customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c884ab-ce0a-4441-b234-5af06983061a",
   "metadata": {},
   "source": [
    "### Expected Probability Alive\n",
    "Let's check the probability our customers are still alive and compare against the MAP results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef25ad6-60ac-4435-9714-39bb393d0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(\n",
    "    nrows=3,\n",
    "    ncols=2,\n",
    "    figsize=(12, 14),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, customer_id in enumerate(example_customer_ids):\n",
    "    ax = axes[i]\n",
    "    demz_alive = pnbd_full.expected_probability_alive(\n",
    "        rfm_sample,\n",
    "        future_t=0,\n",
    "    ).sel(customer_id=customer_id)\n",
    "    map_alive = pnbd_map.expected_probability_alive(rfm_sample, future_t=0).sel(\n",
    "        customer_id=customer_id\n",
    "    )\n",
    "\n",
    "    az.plot_density(demz_alive, hdi_prob=1, colors=\"C1\", shade=0.3, bw=0.005, ax=ax)\n",
    "    ax.axvline(x=map_alive, color=\"C3\", linestyle=\"--\", label=\"MAP\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set(\n",
    "        title=f\"Customer {customer_id}\",\n",
    "        xlabel=\"Probability Alive\",\n",
    "        ylabel=\"Posterior Density\",\n",
    "    )\n",
    "\n",
    "plt.gcf().suptitle(\"Expected Probability Alive\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e235446a-a4ad-4c6e-b296-f3182c12600a",
   "metadata": {},
   "source": [
    "Customer 1413 has a rather low alive probability despite being a frequent purchaser. This would be a good example of a customer to target with a special offer for retention.\n",
    "\n",
    "These probabilities are estimated at time period 0, but we can also estimate the probabilities customers will still be active in the future. Let's calculate the posterior densities 90 time periods from now and compare to the MAP at time period 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5a5bb-1e55-4acb-8cdc-8907ea54d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(\n",
    "    nrows=3,\n",
    "    ncols=2,\n",
    "    figsize=(12, 14),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, customer_id in enumerate(example_customer_ids):\n",
    "    ax = axes[i]\n",
    "    demz_alive = pnbd_full.expected_probability_alive(\n",
    "        rfm_sample,\n",
    "        future_t=90,\n",
    "    ).sel(customer_id=customer_id)\n",
    "    map_alive = pnbd_map.expected_probability_alive(rfm_sample, future_t=0).sel(\n",
    "        customer_id=customer_id\n",
    "    )\n",
    "\n",
    "    az.plot_density(demz_alive, hdi_prob=1, colors=\"C1\", shade=0.3, bw=0.005, ax=ax)\n",
    "    ax.axvline(x=map_alive, color=\"C3\", linestyle=\"--\", label=\"MAP at Time 0\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.set(\n",
    "        title=f\"Customer {customer_id}\",\n",
    "        xlabel=\"Probability Alive\",\n",
    "        ylabel=\"Posterior Density at Time 90\",\n",
    "    )\n",
    "\n",
    "plt.gcf().suptitle(\"Expected Probability Alive Delta\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3ce55-7036-40c5-b72c-2819b4563ee7",
   "metadata": {},
   "source": [
    "Pay attention to the x-axes for each customer - The probabilities barely changed for the *non-repeat* customers, but there is a significant delta for *frequent buyers*.\n",
    "\n",
    "A good rule of thumb is that an alive probability of .25-.30 usually indicates an at-risk or inactive customer. Future projections can give additional insight into customer churn risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bab10f-952c-4d64-910a-fd9f9c8b332d",
   "metadata": {},
   "source": [
    "### Probability of $n$ Purchases over Time $t$\n",
    "\n",
    "Customer 46 is our best customer in this small sample set, and is expected to make at least $15$ purchases over the next $90$ time periods. What is the probability of this many purchases being made, and how will it change over time?\n",
    "\n",
    "Let's plot a heatmap to paint the full picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3fe398-ec38-49c0-a47c-8c5beea9fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays of parameter combinations\n",
    "n_purchases = np.repeat([0, 3, 6, 9, 12, 15], 6)\n",
    "time_periods = np.tile([15, 30, 45, 60, 75, 90], 6)\n",
    "\n",
    "expected_purchase_prob_heatmap = xr.concat(\n",
    "    objs=[\n",
    "        pnbd_map.expected_purchase_probability(\n",
    "            rfm_sample,\n",
    "            n_purchases=params[0],\n",
    "            future_t=params[1],\n",
    "        ).sel(customer_id=46)\n",
    "        for params in zip(n_purchases, time_periods, strict=False)\n",
    "    ],\n",
    "    dim=\"customer_id\",\n",
    ").transpose(..., \"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e83f8e-d298-43d8-999a-189eac8dece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_reshape = expected_purchase_prob_heatmap.values.reshape(6, 6)\n",
    "\n",
    "sb.heatmap(heatmap_reshape, annot=True)\n",
    "\n",
    "plt.xlabel(\"Time Periods\")\n",
    "plt.xticks(np.arange(6) + 0.5, [15, 30, 45, 60, 75, 90], rotation=0)\n",
    "plt.ylabel(\"Number of Purchases\")\n",
    "plt.yticks(np.arange(6) + 0.5, [0, 3, 6, 9, 12, 15], rotation=0)\n",
    "plt.gcf().suptitle(\n",
    "    \"Expected Purchase Probabilities for Customer 46\", fontsize=18, fontweight=\"bold\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5569793-d3e0-4e91-a436-1119d632006b",
   "metadata": {},
   "source": [
    "This heatmap highlights how Customer 46 is expected to make at least 15 purchases *up to* time period 90, but the odds of 15 purchases being made before time period 75 or even time period 60 are slightly higher. Also note these probabilities assume exact expectations (i.e., there's a 6.2% chance of the 15th purchase being made precisely during time period 60.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3bd1b-24d1-40e5-98c1-3757344c7689",
   "metadata": {},
   "source": [
    "### Expected Number of Purchases for New Customers\n",
    "So far we've only been running predictions for existing customers, but we can also estimate the expected number of transactions over time for a new customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cb430-75ce-43ce-bd0d-c82aee1f2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_purchases_over_time_new_customer = xr.concat(\n",
    "    objs=[\n",
    "        pnbd_full.expected_purchases_new_customer(\n",
    "            data=rfm_sample,\n",
    "            t=t,\n",
    "        ).sel(customer_id=1)  # customer_id is arbitrary here\n",
    "        for t in range(90)\n",
    "    ],\n",
    "    dim=\"t\",\n",
    ").transpose(..., \"t\")\n",
    "\n",
    "\n",
    "# plot results\n",
    "ax = plt.axes()\n",
    "\n",
    "az.plot_hdi(\n",
    "    range(90),\n",
    "    expected_purchases_over_time_new_customer,\n",
    "    hdi_prob=0.94,\n",
    "    color=\"C2\",\n",
    "    fill_kwargs={\"alpha\": 0.3, \"label\": \"$94 \\\\%$ HDI\"},\n",
    "    ax=ax,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    range(90),\n",
    "    expected_purchases_over_time_new_customer,\n",
    "    hdi_prob=0.5,\n",
    "    color=\"C2\",\n",
    "    fill_kwargs={\"alpha\": 0.5, \"label\": \"$50 \\\\%$ HDI\"},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.plot(\n",
    "    range(90),\n",
    "    expected_purchases_over_time_new_customer.mean(dim=(\"chain\", \"draw\")),\n",
    "    color=\"C2\",\n",
    "    label=\"posterior mean\",\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set(\n",
    "    title=\"Expected Number of Purchases by New Customers\",\n",
    "    ylabel=\"# of purchases\",\n",
    "    xlabel=\"t\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29171fe9-8c7d-425d-b84f-917bc149e3b3",
   "metadata": {},
   "source": [
    "Let's see how these estimates change when we add covariates to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b668e-a53d-487b-9b05-0090a2dfa2e3",
   "metadata": {},
   "source": [
    "## Time-Invariant Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c4061-6e4b-448f-b266-cbc755736bab",
   "metadata": {},
   "source": [
    "Recall $\\alpha$, and $\\beta$ represent the scale parameters for the purchase and dropout rate distributions, respectively. To model for time-invariant covariates, we simply modify these parameters as follows:\n",
    "\n",
    "$$\\alpha = \\alpha_0e^{-\\gamma_1'z_1}$$\n",
    "$$\\beta = \\beta_0e^{-\\gamma_2'z_2}$$\n",
    "\n",
    "Where $\\gamma_1$ and $\\gamma_2$ are coefficients capturing the impact of the covariates, and $z_1$ and $z_2$ the covariate arrays for each customer.\n",
    "\n",
    "Let's take a look at the covariates available in the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6baa04-0bdc-4683-8fe0-28cc61831474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate raw data by customer id\n",
    "covar_df = raw_data[[\"id\", \"cds_bought\", \"spent\"]].groupby(\"id\").mean().reset_index()\n",
    "\n",
    "# plot covariate histograms\n",
    "_, axes = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    figsize=(10, 5),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "covars = [\"cds_bought\", \"spent\"]\n",
    "colors = [\"C0\", \"C2\"]\n",
    "\n",
    "for ax in zip(axes, covars, colors, strict=False):\n",
    "    ax[0].hist(\n",
    "        x=covar_df[ax[1]],\n",
    "        bins=5,\n",
    "        color=ax[2],\n",
    "    )\n",
    "    ax[0].set(title=f\"{ax[1]}\", xlabel=\"value\", ylabel=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532be650-f3e5-4346-9d53-36c701f148ab",
   "metadata": {},
   "source": [
    "One-tailed distributions with large values like this will complicate model fitting, so let's log and standardize our covariates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba352fb-5ea4-4f9e-84cf-f9db482c770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for covar in [\"cds_bought\", \"spent\"]:\n",
    "    covar_df[f\"log_std_{covar}\"] = np.log(covar_df[covar]).copy()\n",
    "    covar_df[f\"log_std_{covar}\"] -= np.nanmean(covar_df[f\"log_std_{covar}\"])\n",
    "    covar_df[f\"log_std_{covar}\"] /= np.nanstd(covar_df[f\"log_std_{covar}\"])\n",
    "    covar_df[f\"log_std_{covar}\"] = covar_df[f\"log_std_{covar}\"].fillna(0)\n",
    "\n",
    "_, axes = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    figsize=(10, 5),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax in zip(axes, covars, colors, strict=False):\n",
    "    ax[0].hist(\n",
    "        x=covar_df[f\"log_std_{ax[1]}\"],\n",
    "        bins=5,\n",
    "        color=ax[2],\n",
    "    )\n",
    "    ax[0].set(title=f\"transformed {ax[1]}\", xlabel=\"value\", ylabel=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbdaec3-6afc-404c-8b4a-dddce08437a9",
   "metadata": {},
   "source": [
    "To parametrize `ParetoNBDModel` with covariates, join the covariates to the existing RFM data and specify the column names in the `model_config`. Covariates for the purchase and dropout rates can be specified separately, enabling experimentation with various combinations to find what works best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef865f-6ff5-40e5-a914-994e9364b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_covar = rfm_data.merge(covar_df, left_on=\"customer_id\", right_on=\"id\", how=\"inner\")\n",
    "\n",
    "pnbd_covar = clv.ParetoNBDModel(\n",
    "    rfm_covar,\n",
    "    model_config={\n",
    "        \"purchase_covariate_cols\": [\"log_std_cds_bought\", \"log_std_spent\"],\n",
    "        \"dropout_covariate_cols\": [\"log_std_cds_bought\", \"log_std_spent\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "pnbd_covar.build_model()\n",
    "pnbd_covar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8772c-ac54-487f-8b97-7c9888cece4c",
   "metadata": {},
   "source": [
    "The additional parameters are automatically created when covariates are added.\n",
    "\n",
    "Let's do a quick MAP fit and check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1e962-c15a-47d6-a8bd-22cf05480671",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnbd_covar.fit(fit_method=\"map\")\n",
    "\n",
    "print(\"Fitted Model Parameters\")\n",
    "summary = pnbd_covar.fit_summary(\n",
    "    var_names=[\n",
    "        \"r\",\n",
    "        \"alpha_scale\",\n",
    "        \"s\",\n",
    "        \"beta_scale\",\n",
    "        \"purchase_coefficient\",\n",
    "        \"dropout_coefficient\",\n",
    "    ]\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce8fb2-f39c-4d87-9e48-39b1d887dd1e",
   "metadata": {},
   "source": [
    "The `purchase_coefficient` and `dropout_coefficient` parameters indicate the respective impacts of each covariate - a negative sign can be interpreted as \"less likely to make a purchase or drop out\".\n",
    "\n",
    "We can see the average number of CDs per purchase only has a small impact on the time between purchases, but a rather large impact on the dropout rate. Customers who frequently purchase multiple CDs are the least likely to dropout.\n",
    "\n",
    "The average spend per purchase is significant for both purchasing and time until dropout, but note that  if using the [Gamma-Gamma model](https://www.pymc-marketing.io/en/stable/notebooks/clv/gamma_gamma.html) to estimate customer lifetime value per the [Quickstart](https://www.pymc-marketing.io/en/stable/notebooks/clv/clv_quickstart.html), then *average spend cannot be used as a covariate* because an important modeling assumption for the Gamma-Gamma model is that spend and frequency are uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979a8dd-33c6-4937-9969-4937a132f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p pymc,pytensor"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "gamma-gamma model",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
